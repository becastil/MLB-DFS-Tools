"""Utility API for powering the interactive simulation dashboard.

The goal of this module is to surface the latest data generated by the
existing optimizers/simulators so that the React dashboard can visualise it
without relying on mocked values.  The API aggregates data from the CSV files
that the tooling already produces (projections, optimizer exports and GPP
simulation summaries) and exposes a small JSON schema that the front-end can
consume.

Run with::

    uvicorn src.dashboard_api:app --reload

"""

from __future__ import annotations

import logging
import re
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd
from fastapi import FastAPI, HTTPException, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SPAStaticFiles(StaticFiles):
    """Custom StaticFiles handler that serves index.html for unmatched routes (SPA support)."""
    
    async def get_response(self, path: str, scope):
        try:
            return await super().get_response(path, scope)
        except Exception as ex:
            # If we get a 404, serve index.html instead to support client-side routing
            if getattr(ex, 'status_code', None) == 404:
                return await super().get_response("index.html", scope)
            raise ex


BASE_DIR = Path(__file__).resolve().parent.parent
OUTPUT_DIR = BASE_DIR / "output"
FRONTEND_DIST_DIR = BASE_DIR / "frontend" / "dist"


SITE_DIRECTORIES: Dict[str, Path] = {
    "dk": BASE_DIR / "dk_data",
    "fd": BASE_DIR / "fd_data",
    "ikb": BASE_DIR / "ikb_data",
}


@dataclass
class FileInfo:
    path: Path
    modified: datetime
    extra: Dict[str, Optional[int]]


def available_sites() -> List[str]:
    """Return the list of sites that have any supporting data files."""

    sites: List[str] = []
    for site, folder in SITE_DIRECTORIES.items():
        if folder.exists() and any(folder.glob("*.csv")):
            sites.append(site)
            continue

        # fall back to checking the output directory for artefacts
        pattern = f"{site}_*"
        if OUTPUT_DIR.exists() and list(OUTPUT_DIR.glob(pattern)):
            sites.append(site)

    return sorted(set(sites))


def _parse_float(value) -> Optional[float]:
    """Coerce strings such as "12.5%" or "$15" into floats."""

    if value is None:
        return None

    if isinstance(value, (int, float)):
        return float(value)

    stripped = str(value).strip()
    if not stripped or stripped in {"-", "NA", "nan", "None"}:
        return None

    cleaned = (
        stripped.replace("%", "")
        .replace("$", "")
        .replace(",", "")
        .replace("+", "")
    )

    try:
        return float(cleaned)
    except ValueError:
        return None


def _load_csv(path: Path) -> Optional[pd.DataFrame]:
    if not path.exists():
        return None

    try:
        return pd.read_csv(path)
    except pd.errors.EmptyDataError:
        return pd.DataFrame()


def _latest_file(pattern: str) -> Optional[FileInfo]:
    if not OUTPUT_DIR.exists():
        return None

    matches = sorted(OUTPUT_DIR.glob(pattern), key=lambda p: p.stat().st_mtime, reverse=True)
    if not matches:
        return None

    latest = matches[0]
    return FileInfo(
        path=latest,
        modified=datetime.fromtimestamp(latest.stat().st_mtime),
        extra={},
    )


def _load_projections(site: str) -> Tuple[Optional[pd.DataFrame], Optional[FileInfo]]:
    projections_path = SITE_DIRECTORIES.get(site, BASE_DIR / f"{site}_data") / "projections.csv"
    df = _load_csv(projections_path)
    if df is None:
        return None, None

    file_info = FileInfo(
        path=projections_path,
        modified=datetime.fromtimestamp(projections_path.stat().st_mtime),
        extra={},
    )

    df.columns = [column.lower() for column in df.columns]
    return df, file_info


def _load_optimizer_export(site: str) -> Tuple[Optional[pd.DataFrame], Optional[FileInfo]]:
    file_info = _latest_file(f"{site}_optimal_lineups_*.csv")
    if not file_info:
        return None, None

    df = _load_csv(file_info.path)
    return df, file_info


def _load_simulation_lineups(site: str) -> Tuple[Optional[pd.DataFrame], Optional[FileInfo]]:
    file_info = _latest_file(f"{site}_gpp_sim_lineups_*.csv")
    if not file_info:
        return None, None

    match = re.search(r"_(\d+)_(\d+)\.csv$", file_info.path.name)
    if match:
        field_size, iterations = match.groups()
        file_info.extra.update(
            {"field_size": int(field_size), "iterations": int(iterations)}
        )

    df = _load_csv(file_info.path)
    return df, file_info


def _load_simulation_exposure(site: str) -> Tuple[Optional[pd.DataFrame], Optional[FileInfo]]:
    file_info = _latest_file(f"{site}_gpp_sim_player_exposure_*.csv")
    if not file_info:
        return None, None

    df = _load_csv(file_info.path)
    return df, file_info


def _format_timestamp(info: Optional[FileInfo]) -> Optional[str]:
    if not info:
        return None
    return info.modified.strftime("%Y-%m-%d %H:%M:%S")


def _build_metrics(
    projections_df: Optional[pd.DataFrame],
    optimizer_df: Optional[pd.DataFrame],
    simulation_info: Optional[FileInfo],
    sim_lineups: Optional[pd.DataFrame],
) -> List[Dict[str, str]]:
    metrics: List[Dict[str, str]] = []

    if projections_df is not None and not projections_df.empty:
        metrics.append(
            {
                "label": "Total Projections",
                "value": f"{len(projections_df):,}",
                "change": None,
            }
        )

    if simulation_info and simulation_info.extra.get("iterations"):
        iterations = simulation_info.extra["iterations"]
        metrics.append(
            {
                "label": "Sim Iterations",
                "value": f"{iterations:,}",
                "change": None,
            }
        )

    if optimizer_df is not None and not optimizer_df.empty:
        metrics.append(
            {
                "label": "Optimized Lineups",
                "value": f"{len(optimizer_df):,}",
                "change": None,
            }
        )

    if sim_lineups is not None and not sim_lineups.empty:
        win_column = next((col for col in sim_lineups.columns if col.lower().startswith("win")), None)
        if win_column:
            win_average = (
                sim_lineups[win_column]
                .apply(_parse_float)
                .dropna()
                .mean()
            )
            if win_average is not None and not pd.isna(win_average):
                metrics.append(
                    {
                        "label": "Avg. Win %",
                        "value": f"{win_average:.2f}%",
                        "change": None,
                    }
                )

    return metrics


def _build_quick_stats(
    projections_df: Optional[pd.DataFrame],
    optimizer_df: Optional[pd.DataFrame],
    sim_lineups: Optional[pd.DataFrame],
) -> List[Dict[str, str]]:
    stats: List[Dict[str, str]] = []

    if sim_lineups is not None and not sim_lineups.empty:
        stats.append(
            {
                "label": "Lineups Simulated",
                "value": f"{len(sim_lineups):,}",
            }
        )

    if optimizer_df is not None and not optimizer_df.empty:
        stats.append(
            {
                "label": "Optimizer Lineups",
                "value": f"{len(optimizer_df):,}",
            }
        )

    if projections_df is not None and "fpts" in projections_df.columns:
        stats.append(
            {
                "label": "Avg. Projection",
                "value": f"{projections_df['fpts'].mean():.2f}",
            }
        )

    if projections_df is not None and "own%" in projections_df.columns:
        stats.append(
            {
                "label": "Avg. Ownership",
                "value": f"{projections_df['own%'].mean():.2f}%",
            }
        )

    return stats


def _performance_chart(sim_lineups: Optional[pd.DataFrame]) -> List[Dict[str, float]]:
    if sim_lineups is None or sim_lineups.empty:
        return []

    metric_cols = {col.lower(): col for col in sim_lineups.columns}

    projection_col = metric_cols.get("fpts proj".lower())
    ceiling_col = metric_cols.get("ceiling")
    win_col = metric_cols.get("win %".lower())

    sortable = sim_lineups.copy()
    if win_col:
        sortable[win_col] = sortable[win_col].apply(_parse_float)
        sortable = sortable.sort_values(win_col, ascending=False)

    records: List[Dict[str, float]] = []
    for idx, row in sortable.head(12).iterrows():
        records.append(
            {
                "label": f"#{idx + 1}",
                "projection": float(row.get(projection_col, 0) or 0),
                "ceiling": float(row.get(ceiling_col, 0) or 0),
                "winRate": float(_parse_float(row.get(win_col, 0)) or 0),
            }
        )

    return records


def _ownership_chart(exposure_df: Optional[pd.DataFrame]) -> List[Dict[str, float]]:
    if exposure_df is None or exposure_df.empty:
        return []

    df = exposure_df.copy()
    df.columns = [column.strip().lower() for column in df.columns]

    def _col(name: str) -> Optional[str]:
        return next((col for col in df.columns if col.replace(".", "") == name), None)

    player_col = _col("player") or "player"
    sim_col = _col("sim own%")
    proj_col = _col("proj own%")

    if not sim_col or not proj_col:
        return []

    df["simulated"] = df[sim_col].apply(_parse_float)
    df["projected"] = df[proj_col].apply(_parse_float)
    df["leverage"] = df["simulated"] - df["projected"]

    df = df.sort_values("leverage", ascending=False).head(10)

    records: List[Dict[str, float]] = []
    for _, row in df.iterrows():
        records.append(
            {
                "player": row.get(player_col, ""),
                "projected": float(row.get("projected") or 0),
                "simulated": float(row.get("simulated") or 0),
                "leverage": float(row.get("leverage") or 0),
            }
        )

    return records


def _composition_chart(sim_lineups: Optional[pd.DataFrame]) -> List[Dict[str, float]]:
    if sim_lineups is None or sim_lineups.empty:
        return []

    stack_columns = [col for col in sim_lineups.columns if col.lower().startswith("stack")]
    if not stack_columns:
        return []

    counts: Dict[str, int] = {}
    for column in stack_columns:
        for value in sim_lineups[column].dropna():
            name = str(value)
            counts[name] = counts.get(name, 0) + 1

    total = sum(counts.values()) or 1
    return [
        {
            "name": name,
            "value": round(count / total * 100, 2),
        }
        for name, count in sorted(counts.items(), key=lambda x: x[1], reverse=True)[:8]
    ]


def _radar_chart(
    sim_lineups: Optional[pd.DataFrame],
    exposure_df: Optional[pd.DataFrame],
) -> List[Dict[str, float]]:
    if sim_lineups is None or sim_lineups.empty:
        return []

    metric_cols = {col.lower(): col for col in sim_lineups.columns}
    win_col = metric_cols.get("win %".lower())
    top_col = metric_cols.get("top 10%".lower())
    roi_col = metric_cols.get("roi%".lower())
    proj_col = metric_cols.get("fpts proj".lower())

    def _mean(column: Optional[str]) -> float:
        if not column:
            return 0.0
        values = sim_lineups[column].apply(_parse_float).dropna()
        if values.empty:
            return 0.0
        return float(values.mean())

    avg_projection = _mean(proj_col)
    max_projection = _parse_float(sim_lineups[proj_col].max()) if proj_col else None
    projection_score = 0.0
    if avg_projection and max_projection:
        projection_score = min(100.0, (avg_projection / max_projection) * 100.0)

    uniqueness_score = 0.0
    if exposure_df is not None and not exposure_df.empty:
        exposure = exposure_df.copy()
        exposure.columns = [column.strip().lower() for column in exposure.columns]
        proj_own_col = next(
            (col for col in exposure.columns if col.replace(".", "") == "proj own%"),
            None,
        )
        if proj_own_col:
            ownership = exposure[proj_own_col].apply(_parse_float).dropna()
            if not ownership.empty:
                uniqueness_score = max(0.0, 100.0 - float(ownership.mean()))

    radar = [
        {"stat": "Win Rate", "value": round(_mean(win_col), 2)},
        {"stat": "Top Finish", "value": round(_mean(top_col), 2)},
        {"stat": "ROI", "value": round(_mean(roi_col), 2)},
        {"stat": "Projection", "value": round(projection_score, 2)},
        {"stat": "Uniqueness", "value": round(uniqueness_score, 2)},
    ]

    return radar


def _contest_table(
    site: str,
    sim_lineups: Optional[pd.DataFrame],
    sim_info: Optional[FileInfo],
) -> List[Dict[str, Optional[float]]]:
    if sim_lineups is None or sim_lineups.empty:
        return []

    metric_cols = {col.lower(): col for col in sim_lineups.columns}
    projection_col = metric_cols.get("fpts proj".lower())
    roi_col = metric_cols.get("roi%".lower())
    avg_return_col = metric_cols.get("avg. return".lower())

    top_projection = None
    avg_projection = None
    avg_roi = None
    avg_return = None

    if projection_col:
        projections = sim_lineups[projection_col].apply(_parse_float).dropna()
        if not projections.empty:
            top_projection = float(projections.max())
            avg_projection = float(projections.mean())

    if roi_col:
        roi_values = sim_lineups[roi_col].apply(_parse_float).dropna()
        if not roi_values.empty:
            avg_roi = float(roi_values.mean())

    if avg_return_col:
        returns = sim_lineups[avg_return_col].apply(_parse_float).dropna()
        if not returns.empty:
            avg_return = float(returns.mean())

    field_size = sim_info.extra.get("field_size") if sim_info else None

    return [
        {
            "name": f"{site.upper()} Simulation",
            "entries": field_size,
            "topScore": top_projection,
            "avgScore": avg_projection,
            "avgReturn": avg_return,
            "roi": avg_roi,
        }
    ]


def _lineup_preview(sim_lineups: Optional[pd.DataFrame]) -> List[Dict[str, object]]:
    if sim_lineups is None or sim_lineups.empty:
        return []

    columns = list(sim_lineups.columns)
    metric_index = next(
        (idx for idx, col in enumerate(columns) if col.lower().startswith("fpts")),
        len(columns),
    )
    roster_columns = columns[:metric_index]

    metric_cols = {col.lower(): col for col in columns[metric_index:]}
    projection_col = metric_cols.get("fpts proj".lower())
    win_col = metric_cols.get("win %".lower())
    roi_col = metric_cols.get("roi%".lower())

    preview: List[Dict[str, object]] = []
    sortable = sim_lineups.copy()
    if win_col:
        sortable[win_col] = sortable[win_col].apply(_parse_float)
        sortable = sortable.sort_values(win_col, ascending=False)

    for _, row in sortable.head(8).iterrows():
        lineup = [str(row[col]) for col in roster_columns]
        preview.append(
            {
                "lineup": lineup,
                "projection": float(row.get(projection_col, 0) or 0),
                "winPct": float(_parse_float(row.get(win_col, 0)) or 0),
                "roi": float(_parse_float(row.get(roi_col, 0)) or 0),
            }
        )

    return preview


def _exposure_table(exposure_df: Optional[pd.DataFrame]) -> List[Dict[str, float]]:
    if exposure_df is None or exposure_df.empty:
        return []

    df = exposure_df.copy()
    df.columns = [column.strip().lower() for column in df.columns]

    player_col = next((col for col in df.columns if col.replace(".", "") == "player"), None)
    win_col = next((col for col in df.columns if col.startswith("win")), None)
    top_col = next((col for col in df.columns if col.startswith("top1")), None)
    cash_col = next((col for col in df.columns if col.startswith("cash")), None)
    sim_col = next((col for col in df.columns if col.startswith("sim own")), None)
    proj_col = next((col for col in df.columns if col.startswith("proj own")), None)

    records: List[Dict[str, float]] = []
    for _, row in df.head(20).iterrows():
        records.append(
            {
                "player": row.get(player_col, ""),
                "winPct": float(_parse_float(row.get(win_col, 0)) or 0),
                "topPct": float(_parse_float(row.get(top_col, 0)) or 0),
                "cashPct": float(_parse_float(row.get(cash_col, 0)) or 0),
                "simOwn": float(_parse_float(row.get(sim_col, 0)) or 0),
                "projOwn": float(_parse_float(row.get(proj_col, 0)) or 0),
            }
        )

    return records


def build_dashboard_payload(site: str) -> Dict[str, object]:
    projections_df, projections_info = _load_projections(site)
    optimizer_df, optimizer_info = _load_optimizer_export(site)
    sim_lineups, sim_info = _load_simulation_lineups(site)
    exposure_df, exposure_info = _load_simulation_exposure(site)

    datasets = (projections_df, optimizer_df, sim_lineups, exposure_df)
    has_data = any(
        dataset is not None and not (hasattr(dataset, "empty") and dataset.empty)
        for dataset in datasets
    )

    payload: Dict[str, object] = {
        "site": site,
        "metrics": _build_metrics(projections_df, optimizer_df, sim_info, sim_lineups),
        "quickStats": _build_quick_stats(projections_df, optimizer_df, sim_lineups),
        "performanceChart": _performance_chart(sim_lineups),
        "ownershipChart": _ownership_chart(exposure_df),
        "compositionChart": _composition_chart(sim_lineups),
        "radarChart": _radar_chart(sim_lineups, exposure_df),
        "contestTable": _contest_table(site, sim_lineups, sim_info),
        "lineupPreview": _lineup_preview(sim_lineups),
        "playerExposure": _exposure_table(exposure_df),
        "files": {
            "projections": str(projections_info.path) if projections_info else None,
            "optimizer": str(optimizer_info.path) if optimizer_info else None,
            "simulation": str(sim_info.path) if sim_info else None,
            "playerExposure": str(exposure_info.path) if exposure_info else None,
        },
        "lastUpdated": {
            "projections": _format_timestamp(projections_info),
            "optimizer": _format_timestamp(optimizer_info),
            "simulation": _format_timestamp(sim_info),
            "playerExposure": _format_timestamp(exposure_info),
        },
        "hasData": has_data,
    }

    payload["projectionSample"] = []
    if projections_df is not None and not projections_df.empty:
        sample_columns = [col for col in ["name", "team", "pos", "fpts", "own%"] if col in projections_df.columns]
        if sample_columns:
            payload["projectionSample"] = (
                projections_df[sample_columns]
                .sort_values(by=sample_columns[-1], ascending=False)
                .head(12)
                .to_dict(orient="records")
            )

    return payload


app = FastAPI(title="Simulation Dashboard API")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

logger.info(f"Checking for frontend bundle at: {FRONTEND_DIST_DIR}")
logger.info(f"Current working directory: {Path.cwd()}")
logger.info(f"Base directory: {BASE_DIR}")

if FRONTEND_DIST_DIR.exists():
    logger.info(f"✓ Frontend dist directory exists: {FRONTEND_DIST_DIR}")
    
    # List contents of dist directory for debugging
    dist_contents = list(FRONTEND_DIST_DIR.iterdir())
    logger.info(f"Contents of {FRONTEND_DIST_DIR}: {[f.name for f in dist_contents]}")
    
    INDEX_FILE = FRONTEND_DIST_DIR / "index.html"
    if INDEX_FILE.exists():
        logger.info(f"✓ Frontend bundle found at {FRONTEND_DIST_DIR}")
        logger.info(f"✓ index.html size: {INDEX_FILE.stat().st_size} bytes")
        logger.info(f"✓ Mounting React SPA at / with index file: {INDEX_FILE}")
        
        # Mount static assets (CSS, JS, images) with proper caching
        static_assets_dir = FRONTEND_DIST_DIR / "assets"
        if static_assets_dir.exists():
            assets_contents = list(static_assets_dir.iterdir())
            logger.info(f"✓ Assets directory found with {len(assets_contents)} files")
            app.mount(
                "/assets", 
                StaticFiles(directory=static_assets_dir), 
                name="static_assets"
            )
            logger.info(f"✓ Mounted static assets at /assets from {static_assets_dir}")
        else:
            logger.warning(f"⚠ Assets directory not found: {static_assets_dir}")
        
        # Mount the SPA with fallback to index.html for client-side routing
        app.mount(
            "/",
            SPAStaticFiles(directory=FRONTEND_DIST_DIR, html=True),
            name="dashboard",
        )
        logger.info("✓ Successfully mounted React SPA")
    else:
        logger.error(f"✗ Frontend dist directory exists but index.html missing: {INDEX_FILE}")
        logger.error(f"  Available files in dist: {[f.name for f in FRONTEND_DIST_DIR.iterdir()]}")
else:
    logger.error(f"✗ Frontend dist directory not found: {FRONTEND_DIST_DIR}")
    logger.error(f"  Current directory contents: {[f.name for f in BASE_DIR.iterdir() if f.is_dir()]}")
    
    # Check if frontend directory exists at all
    frontend_dir = BASE_DIR / "frontend"
    if frontend_dir.exists():
        logger.info(f"Frontend directory exists: {frontend_dir}")
        frontend_contents = [f.name for f in frontend_dir.iterdir()]
        logger.info(f"Frontend directory contents: {frontend_contents}")
    else:
        logger.error(f"Frontend directory does not exist: {frontend_dir}")
    
    logger.error("  The React dashboard will not be served - only API endpoints available")
    
    @app.get("/", include_in_schema=False)
    async def missing_frontend() -> Dict[str, str]:
        """Provide helpful message when frontend bundle is missing."""
        return {
            "error": "Frontend bundle not available",
            "message": "The React dashboard is not available. Only API endpoints are accessible.",
            "api_docs": "/docs",
            "health_check": "/api/health",
            "available_sites": "/api/dashboard/sites"
        }


@app.get("/api/health", include_in_schema=False)
def healthcheck() -> Dict[str, str]:
    """Provide a friendly landing response for platform health checks."""

    return {
        "status": "ok",
        "message": "MLB DFS Dashboard API is running.",
        "docs": "/docs",
        "sites": "/api/dashboard/sites",
        "dashboard": "/",
    }


@app.get("/favicon.ico", include_in_schema=False)
def favicon() -> Response:
    """Return an empty response so the platform does not log a 404."""

    return Response(status_code=204)


@app.get("/api/dashboard/sites")
def get_sites() -> Dict[str, List[str]]:
    sites = available_sites()
    if not sites:
        # expose the known keys so the UI can still render controls
        sites = sorted(SITE_DIRECTORIES.keys())
    return {"sites": sites}


@app.get("/api/dashboard/site/{site}")
def get_site_dashboard(site: str) -> Dict[str, object]:
    site = site.lower()
    if site not in SITE_DIRECTORIES:
        raise HTTPException(status_code=404, detail="Unknown site.")

    return build_dashboard_payload(site)


@app.get("/api/dashboard")
def get_default_dashboard() -> Dict[str, object]:
    sites = available_sites()
    target_site = sites[0] if sites else next(iter(SITE_DIRECTORIES.keys()))
    data = build_dashboard_payload(target_site)
    data["availableSites"] = sites or list(SITE_DIRECTORIES.keys())
    return data


if __name__ == "__main__":  # pragma: no cover - manual execution helper
    import uvicorn

    uvicorn.run("src.dashboard_api:app", host="0.0.0.0", port=8000, reload=True)

